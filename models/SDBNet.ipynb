# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
# 
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
# 
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

from functools import reduce
import tensorflow as tf
from tensorflow import keras
import numpy as np
import tensorflow.keras.backend as K


#### Custom function for conv2d: conv_block
def conv_block(inputs, conv_type, kernel, kernel_size, strides, padding='same', relu=True, use_bias=True):
  
      if(conv_type == 'ds'):
        x = tf.keras.layers.SeparableConv2D(kernel, kernel_size, padding=padding, strides = strides)(inputs)
      else:
        x = tf.keras.layers.Conv2D(kernel, kernel_size, padding=padding, strides = strides)(inputs)  

      x = tf.keras.layers.BatchNormalization()(x)

      if (relu):
        #x = tf.keras.activations.relu(x)
        x = tf.keras.layers.Activation(lambda x: tf.nn.swish(x))(x)
      return x

#Shallow_block
def shallow_block(inputs, kernel, kernel_size, strides):
  
      x = conv_block(inputs, 'ds', kernel, (3, 3), strides = (2, 2))  
      x = conv_block(x, 'ds', kernel, (1, 1), strides = (1, 1))  

      y = conv_block(inputs, 'conv', kernel, (1, 1), strides = (strides, strides)) 

      Shallow_output = tf.keras.layers.add([x, y])

      return x

def MB_block(inputs, filters, expand_filters, kernel, strides=(1, 1), r=False):
    
    x = conv_block(inputs, 'conv', expand_filters, (1, 1), strides=(1, 1))

    x = tf.keras.layers.DepthwiseConv2D(kernel, strides=strides, dilation_rate=(1,1), padding='same')(x)
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.activations.relu(x)

    x = conv_block(x, 'conv', filters, (1, 1), strides=(1, 1), padding='same', relu=False) 

    if r:
        x = tf.keras.layers.add([x, inputs])
    return x

def _SDB_bottleneck(inputs, filters, kernel, t, strides, r=False):
    
    tchannel = filters
    tchannel1 = tchannel
    tchannel2 = tchannel * 2
    tchannel3 = tchannel * 3
    tchannel4 = tchannel * 4
    
    if r:
        x1 = MB_block(inputs, tchannel, tchannel2, kernel, strides=(1,1))
        x2 = MB_block(x1, tchannel, tchannel4, kernel, strides=(1,1))
        x2 = tf.keras.layers.UpSampling2D(size=(1, 1), interpolation='bilinear')(x2)
        x4 = MB_block(x2, tchannel, tchannel4, kernel, strides=(1, 1))

    else:
        x1 = MB_block(inputs, tchannel, tchannel2, kernel, strides=(strides,strides))
        x2 = MB_block(x1, tchannel, tchannel3, kernel, strides=(strides,strides))
        x2 = tf.keras.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x2)
        x4 = MB_block(x2, tchannel, tchannel4, kernel, strides=(1, 1))
    
    SDB_block = tf.keras.layers.add([x1, x4])    

    if r:
        SDB_block = tf.keras.layers.add([SDB_block, inputs])
    return SDB_block


"""#### Bottleneck custom method"""

def bottleneck_block(inputs, filters, kernel, t, strides, n):
      x = _SDB_bottleneck(inputs, filters, kernel, t, strides)

      for i in range(1, n):
        x = _SDB_bottleneck(x, filters, kernel, t, 1, True)

      return x        
 
# Feature Refinement block   
def FR_block(inputs, kernel):
  
      x = conv_block(inputs, 'conv', kernel, (3, 3), strides = (1, 1))
      x = tf.nn.avg_pool2d(x, kernel, 1, 'SAME')
      x = tf.keras.layers.Conv2D(kernel, 1, padding='same', strides = 1)(x)
      x = conv_block(x, 'conv', kernel, (1, 1), strides = (1, 1))  
      x = tf.keras.layers.BatchNormalization()(x)
      x = tf.keras.activations.sigmoid(x)
      x = tf.keras.layers.Multiply()([x, inputs])

      return x

# Semantic aggregation
def SA_block(f1, f2, kernel=256):
    SA = tf.keras.layers.Concatenate()([f1, f2])
    SA = conv_block(SA, 'conv', kernel, (1, 1), strides = (1, 1))
    atten = tf.nn.avg_pool2d(SA, kernel, 1, 'SAME')
    atten = tf.keras.layers.Conv2D(kernel, 1, padding='same', strides = 1)(atten)
    atten = tf.keras.activations.relu(atten)
    
    atten = tf.keras.layers.Conv2D(kernel, 1, padding='same', strides = 1)(atten)
    atten = tf.keras.activations.sigmoid(atten)
    SA_atten = tf.keras.layers.Multiply()([atten, SA])
    SA_out = tf.keras.layers.add([SA_atten, SA])
    
    return SA_out      


def model(num_classes=19, input_size=(1024, 2048, 3)):

      # Input Layer
      input_layer = tf.keras.layers.Input(shape=input_size, name = 'input_layer')

      ## Step 1: Learning to DownSample
      input1 = conv_block(input_layer, 'conv', 32, (3, 3), strides = (2, 2))
      input2 = conv_block(input1, 'ds', 48, (3, 3), strides = (2, 2))

      #shallow branch
      S3 = shallow_block(input2, 64, (3, 3), strides=2)   
      S4 = shallow_block(S3, 96, (3, 3), strides=2)
      S5 = shallow_block(S4, 128, (3, 3), strides=2)

      #deep branch  
      D3 = bottleneck_block(input2, 64, (3, 3), t=1, strides=2, n=2)
      D3 = tf.keras.layers.add([D3, S3])

      D4 = bottleneck_block(D3, 96, (3, 3), t=1, strides=2, n=2)
      D4 = tf.keras.layers.add([D4, S4])

      D5 = bottleneck_block(D4, 128, (3, 3), t=1, strides=2, n=2)
      D5 = tf.keras.layers.add([D5, S5]) 
    
      F5 = D5
	    #channel reduction
      F5_in = tf.keras.layers.Conv2D(64, 1, 1, padding='same', activation=None)(F5)
      F5_in = tf.keras.layers.BatchNormalization()(F5_in)
      F5_in = FR_block(F5_in, 64)

      SF5 = S5
	    #channel reduction
      SF5_in = tf.keras.layers.Conv2D(64, 1, 1, padding='same', activation=None,)(SF5)
      SF5_in = tf.keras.layers.BatchNormalization()(SF5_in)
      #SF5_in = FR_block(SF5_in, 64)
      
      F4 = D4
	    #channel reduction
      F4_in = tf.keras.layers.Conv2D(64, 1, 1, padding='same', activation=None,)(F4)
      F4_in = tf.keras.layers.BatchNormalization()(F4_in)
      F4_in = FR_block(F4_in, 64)

      SF4 = S4
	    #channel reduction
      SF4_in = tf.keras.layers.Conv2D(64, 1, 1, padding='same', activation=None,)(SF4)
      SF4_in = tf.keras.layers.BatchNormalization()(SF4_in)
      SF4_in = FR_block(SF4_in, 64)
      
      F3 = D3
	    #channel reduction
      F3_in = tf.keras.layers.Conv2D(64, 1, 1, padding='same', activation=None,)(F3)
      F3_in = tf.keras.layers.BatchNormalization()(F3_in)
      
      SF3 = S3
	    #channel reduction
      SF3_in = tf.keras.layers.Conv2D(64, 1, 1, padding='same', activation=None,)(SF3)
      SF3_in = tf.keras.layers.BatchNormalization()(SF3_in)

      F5_U = tf.keras.layers.UpSampling2D()(F5_in)
      F4_td = tf.keras.layers.Add()([F4_in, F5_U])

	    #Semantic aggregation between two feature maps
      ff4 = SA_block(F4_td, SF4_in, kernel=64)

      F4_U = tf.keras.layers.UpSampling2D()(ff4)
      F3_td = tf.keras.layers.Add()([F3_in, F4_U])
	
	  #Semantic aggregation between two feature maps
      ff3 = SA_block(F3_td, SF3_in, kernel=64)

      ## Step 4: Classifier

      classifier = tf.keras.layers.SeparableConv2D(64, (3, 3), padding='same', strides = (1, 1), name = 'DSConv1_classifier')(ff3)
      classifier = tf.keras.layers.BatchNormalization()(classifier)
      classifier = tf.keras.layers.Activation(lambda x: tf.nn.swish(x))(classifier)

      classifier = tf.keras.layers.SeparableConv2D(48, (3, 3), padding='same', strides = (1, 1), name = 'DSConv2_classifier')(classifier)
      classifier = tf.keras.layers.BatchNormalization()(classifier)
      classifier = tf.keras.layers.Activation(lambda x: tf.nn.swish(x))(classifier)

      classifier = tf.keras.layers.Conv2D(num_classes, 1, 1, padding='same', activation=None,
                                          kernel_regularizer=keras.regularizers.l2(0.00004),
                                          bias_regularizer=keras.regularizers.l2(0.00004))(classifier)

      classifier = tf.keras.layers.Dropout(0.35)(classifier) 
      classifier = tf.dtypes.cast(classifier, tf.float32)
      classifier = tf.keras.activations.softmax(classifier)
      
      classifier = tf.keras.layers.UpSampling2D(size=(8, 8), interpolation='bilinear')(classifier)

      SDBNet = tf.keras.Model(inputs = input_layer , outputs = classifier, name = 'SDBNet')

      return SDBNet